{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取保存的历代.npy文件，包含全部X与F，预备进行相关性分析\n",
    "**独立代码块，需要自定义chkpt_dir与n_gen**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "matplotlib.rcParams[\"font.sans-serif\"] = [\"SimHei\"]  \n",
    "matplotlib.rcParams[\"axes.unicode_minus\"] = False    # 正常显示负号\n",
    "from pymoo.indicators.hv import HV\n",
    "\n",
    "chkpt_dir = r\"F:\\ResearchMainStream\\0.ResearchBySection\\C.动力学模型\\C23参数优化\\参数优化实现\\ParallelSweepSimpack\\结果分析组\\NSGA完整迭代计算结果\\0812-NSGA2-Seed2-100群200代\"\n",
    "\n",
    "n_gen = 200  # 总迭代轮次\n",
    "n_obj = 3   # 目标维度\n",
    "n_var = 12  # 设计变量(参数)维度\n",
    "\n",
    "all_X_history = []  # 用于收集所有代次的 X\n",
    "all_F_history = []  # 用于收集所有代次的 F\n",
    "\n",
    "for gen in range(1, n_gen + 1):\n",
    "    # 注意这里 filename 要用 f\"generation_{gen}.npz\"\n",
    "    filename = os.path.join(chkpt_dir, f\"generation_{gen}.npz\")\n",
    "    \n",
    "    # 读取 .npz 文件\n",
    "    with np.load(filename) as data:\n",
    "        X = data[\"X\"]  # shape = (pop_size, n_var)\n",
    "        F = data[\"F\"]  # shape = (pop_size, n_obj)\n",
    "    \n",
    "    # 将当前代的数据放入 list\n",
    "    all_X_history.append(X)\n",
    "    all_F_history.append(F)\n",
    "\n",
    "# 现在 all_X_history 和 all_F_history 都是 list，每个元素是 (pop_size, n_var) or (pop_size, n_obj)\n",
    "# 如果想把所有代次堆成一个大的 2D 矩阵，可以用 np.vstack:\n",
    "\n",
    "all_X_history = np.vstack(all_X_history)  # shape = (n_gen * pop_size, n_var)\n",
    "all_F_history = np.vstack(all_F_history)  # shape = (n_gen * pop_size, n_obj)\n",
    "\n",
    "print(\"all_X_history shape:\", all_X_history.shape)\n",
    "print(\"all_F_history shape:\", all_F_history.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 可视化 {X1,…,X12}与 {Y1,Y2,Y3}之间的相关系数子矩阵\n",
    "**依赖于X与F的.npy数据导入**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "param_names = [f\"X{i+1}\" for i in range(12)]\n",
    "target_names = [f\"Y{i+1}\" for i in range(3)]\n",
    "\n",
    "df_X = pd.DataFrame(all_X_history, columns=param_names)\n",
    "df_F = pd.DataFrame(all_F_history, columns=target_names)\n",
    "\n",
    "# 计算一个完整的相关矩阵(15x15)，然后只取想看的 12x3 或 3x12 子矩阵\n",
    "df_all = pd.concat([df_X, df_F], axis=1)\n",
    "\n",
    "corr_matrix = df_all.corr(method=\"pearson\")  # 形状(15, 15)\n",
    "\n",
    "# 只截取 X1~X12 与 Y1~Y3 的部分, 这会是形状 (12, 3)\n",
    "sub_corr = corr_matrix.loc[param_names, target_names]\n",
    "\n",
    "print(\"子矩阵 shape:\", sub_corr.shape)\n",
    "print(sub_corr)\n",
    "\n",
    "# 可视化, 让 x 轴显示 Y1~Y3, y 轴显示 X1~X12\n",
    "plt.figure(figsize=(6, 8))\n",
    "sns.heatmap(sub_corr, annot=True, cmap=\"coolwarm\", center=0)\n",
    "plt.title(\"Correlation of X1..X12 vs. Y1..Y3\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算 Sobol 主效应 (S1) 和全效应 (ST)，并绘制指数热力图\n",
    "**依赖于X与F的.npy数据导入**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# SALib 1.5.1+ 官方建议使用 `sobol.sample` 而不是 `saltelli.sample`\n",
    "from SALib.sample import sobol\n",
    "from SALib.analyze import sobol as sobol_analyze\n",
    "\n",
    "# ============ 1. 载入已有数据 ============\n",
    "X = all_X_history  \n",
    "Y = all_F_history  \n",
    "print(\"X shape:\", X.shape)  # (5808, 12)\n",
    "print(\"Y shape:\", Y.shape)  # (5808, 3)\n",
    "\n",
    "# ============ 2. 多输出随机森林训练 ============\n",
    "# 拆分训练集、测试集 (80% 训练 + 20% 测试)\n",
    "# test_size = 0.2 表示划分方式，可自行调大或调小\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, \n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)\n",
    "# 构造多输出随机森林\n",
    "# 重要参数解释:\n",
    "# - n_estimators=100: 随机森林中树的数量，越多越稳定但计算更慢\n",
    "# - max_depth=None: 默认为None表示树可以不受限地生长，视数据量而定\n",
    "# - random_state=42: 随机种子，保证结果可复现\n",
    "rf = RandomForestRegressor(n_estimators=100, \n",
    "                           max_depth=None, \n",
    "                           random_state=42)\n",
    "print(\"[Info] 开始训练多输出随机森林...\")\n",
    "rf.fit(X_train, Y_train)  # Y_train.shape=(n_samples, 3) 多输出回归\n",
    "# 预测测试集\n",
    "Y_pred = rf.predict(X_test)  # shape=(test_size, 3)\n",
    "# 分别计算每个目标的 MSE\n",
    "mse_list = []\n",
    "for j in range(Y.shape[1]):\n",
    "    mse_j = mean_squared_error(Y_test[:, j], Y_pred[:, j])\n",
    "    mse_list.append(mse_j)\n",
    "    print(f\"RandomForest for Y{j+1}, Test MSE = {mse_j:.4f}\")\n",
    "\n",
    "# ============ 3. 全局灵敏度分析 (Sobol) ============\n",
    "# 3.1 定义输入参数范围 (bounds)\n",
    "# 这里简单取历史数据的最小值 & 最大值，也可以使用工程先验信息\n",
    "X_min = X.min(axis=0)  # shape=(12,)\n",
    "X_max = X.max(axis=0)  # shape=(12,)\n",
    "problem = {\n",
    "    'num_vars': 12,\n",
    "    'names': param_names,\n",
    "    'bounds': [[X_min[i], X_max[i]] for i in range(12)]\n",
    "}\n",
    "\n",
    "# 采样数量(越大结果越稳定, 但计算量增加)\n",
    "# 注意 Sobol 序列收敛性最好使用 2^n, 例如 512, 1024, 2048\n",
    "N_base = 256  \n",
    "print(\"[Info] 使用 Sobol 采样, N_base =\", N_base)\n",
    "param_values = sobol.sample(problem, N_base, calc_second_order=True)\n",
    "print(\"param_values shape:\", param_values.shape)\n",
    "\n",
    "# 3.2 评估代理模型 (rf) 在采样点的预测值\n",
    "# 由于是多输出, Y_sobol_pred.shape = (param_values.shape[0], 3)\n",
    "Y_sobol_pred = rf.predict(param_values)  \n",
    "\n",
    "S1_list = []  # 用于存放3个目标的 S1 (each is shape=(12,))\n",
    "ST_list = []  # 用于存放3个目标的 ST\n",
    "\n",
    "# 3.3 分别对每个目标做 Sobol 指数分析\n",
    "for j in range(Y.shape[1]):\n",
    "    print(f\"\\n=== Sobol Analysis for Y{j+1} ===\")\n",
    "    # 当前目标在所有采样点的值\n",
    "    current_output = Y_sobol_pred[:, j]\n",
    "\n",
    "    # 做 Sobol 分析\n",
    "    Si = sobol_analyze.analyze(problem, current_output, calc_second_order=True)\n",
    "\n",
    "    # 打印主效应 (S1) 和全效应 (ST)\n",
    "    # 注意: S1, ST 都是长度12的数组, 对应 X1..X12\n",
    "    s1 = Si['S1']  # shape=(12,)\n",
    "    st = Si['ST']  # shape=(12,)\n",
    "    print(\"Sobol First Order Indices (S1):\", s1)\n",
    "    print(\"Sobol Total Effect Indices (ST):\", st)\n",
    "\n",
    "    # 保存到列表\n",
    "    S1_list.append(s1)\n",
    "    ST_list.append(st)\n",
    "\n",
    "# 将list转换为矩阵, shape=(3, 12) => 行=目标, 列=参数\n",
    "S1_array = np.array(S1_list)  # shape=(3,12)\n",
    "ST_array = np.array(ST_list)  # shape=(3,12)\n",
    "\n",
    "# 转置后, shape=(12,3) => 行=参数 X1..X12, 列=目标 Y1..Y3\n",
    "S1_array_t = S1_array.T\n",
    "ST_array_t = ST_array.T\n",
    "\n",
    "# 画热力图（行 = X, 列 = Y）\n",
    "# 以全效应 (ST)为例：\n",
    "param_names = [f\"X{i+1}\" for i in range(12)]  # 行标签\n",
    "target_names = [f\"Y{i+1}\" for i in range(3)]  # 列标签\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "sns.heatmap(ST_array_t,       # shape=(12,3)\n",
    "            annot=True,       # 在格子中显示数值\n",
    "            cmap=\"coolwarm\",  # 颜色方案，可换成 \"bwr\", \"RdBu_r\", etc.\n",
    "            vmin=0, vmax=0.8,  \n",
    "            xticklabels=target_names,\n",
    "            yticklabels=param_names\n",
    "           )\n",
    "\n",
    "plt.title(\"Sobol ST Indices (X in rows, Y in columns)\")\n",
    "plt.xlabel(\"Objectives\")\n",
    "plt.ylabel(\"Parameters\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分析不同型式双牵引拉杆对于动力学性能的影响"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: 读取数据 & 构造 D、可视化字体设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据并构造 D（<0 为 Λ 型；≥0 为 V/一般型）\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# ==== 显式可改：Excel 文件路径与工作表名 ====\n",
    "FILE  = Path(r\"F:/ResearchMainStream/0.ResearchBySection/C.动力学模型/C23参数优化/参数优化实现/ParallelSweepSimpack/结果分析组/后处理-NSGA23算法效能对比/merged_nsga_23nd.xlsx\")\n",
    "SHEET = \"merged_nsga_23nd\"   # 若名称不同，改这里\n",
    "\n",
    "df = pd.read_excel(FILE, sheet_name=SHEET)\n",
    "\n",
    "# ==== 列名重命名（可根据文件调整映射）====\n",
    "# 以如下表头为例: X1 X2 X3 X4 X5 X6 X7 X8 X9 X10 X11 X12 F0 F1 F2\n",
    "rename_map = {\n",
    "    \"X2\":  \"Kpx\",\n",
    "    \"X10\": \"Lx1\",\n",
    "    \"X11\": \"Lx2\",\n",
    "    \"X12\": \"Lx3\",\n",
    "    \"X8\":  \"Cld\",\n",
    "    \"X9\":  \"Chx\",\n",
    "    \"F1\":  \"Wear\",  # 磨耗数 (wear number)\n",
    "    \"F0\":  \"Y1\",    # 临界速度 critical speed，定义为 Y1 = -Vc[m/s]\n",
    "    \"F2\":  \"Y3\",    # 平稳性指标 (ride comfort index)\n",
    "}\n",
    "\n",
    "df = df.rename(columns=rename_map)\n",
    "\n",
    "# 只保留本次分析需要列，去缺失\n",
    "use_cols = [\"Kpx\", \"Lx1\", \"Lx2\", \"Lx3\", \"Cld\", \"Chx\", \"Wear\", \"Y1\", \"Y3\"]\n",
    "df = df[use_cols].dropna().copy()\n",
    "\n",
    "# 几何差值 D；并派生 Vc(km/h) 用于阅读（Y1 是 -Vc[m/s]）\n",
    "df[\"D\"] = df[\"Lx1\"] - df[\"Lx2\"]\n",
    "df[\"Vc_kmh\"] = (-df[\"Y1\"]) * 3.6\n",
    "\n",
    "# 中文字体设置\n",
    "plt.rcParams[\"font.sans-serif\"] = [\"SimHei\", \"Microsoft YaHei\", \"Arial Unicode MS\"]\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "print(df.describe(include=\"all\").T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: 偏相关——在相同控制变量下，计算 r(D, Y | controls) 与 p 值\n",
    "D 与磨耗（Y2）的散点 + 皮尔逊/斯皮尔曼相关"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "r_p = pearsonr(df[\"D\"], df[\"Wear\"]).statistic\n",
    "r_s = spearmanr(df[\"D\"], df[\"Wear\"]).statistic\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(df[\"D\"], df[\"Wear\"], s=20, alpha=0.8)\n",
    "plt.axvline(0, linestyle=\"--\", linewidth=1)  # D=0 分界线：左侧为 Λ 型\n",
    "plt.xlabel(\"D = Lx1 - Lx2（<0 为 Λ 型）\")\n",
    "plt.ylabel(\"磨耗数 (Y2)\")\n",
    "plt.title(f\"D 与磨耗 (Y2) | Pearson r={r_p:.3f}  Spearman ρ={r_s:.3f}\")\n",
    "plt.grid(True, linewidth=0.3, alpha=0.6)\n",
    "# plt.savefig(\"scatter_D_vs_Wear.png\", dpi=220, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: OLS(HC3) 显著性检验：Y ~ D + Kpx + Cld + Chx + Lx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# 回归：Y2（磨耗）\n",
    "X = df[[\"D\", \"Kpx\", \"Cld\", \"Chx\", \"Lx3\"]].astype(float)\n",
    "X = sm.add_constant(X)\n",
    "y = df[\"Wear\"].astype(float)\n",
    "\n",
    "res_y2 = sm.OLS(y, X).fit(cov_type=\"HC3\")  # 异方差稳健标准误\n",
    "print(res_y2.summary())\n",
    "\n",
    "# 计算 D 的 partial R^2（由 t 值换算）；同时给出标准化系数\n",
    "t_D = res_y2.tvalues[\"D\"]\n",
    "df_resid = res_y2.df_resid\n",
    "partial_R2_y2 = (t_D*t_D) / (t_D*t_D + df_resid)\n",
    "\n",
    "# 标准化系数（z-score 后再回归）\n",
    "Z = df[[\"Wear\",\"D\",\"Kpx\",\"Cld\",\"Chx\",\"Lx3\"]].apply(lambda s: (s - s.mean())/s.std(ddof=0))\n",
    "res_y2_std = sm.OLS(Z[\"Wear\"], sm.add_constant(Z[[\"D\",\"Kpx\",\"Cld\",\"Chx\",\"Lx3\"]])).fit()\n",
    "beta_std_y2 = res_y2_std.params[\"D\"]\n",
    "\n",
    "print(f\"\\n[Y2] coef(D)={res_y2.params['D']:.4g}, t={t_D:.3f}, p={res_y2.pvalues['D']:.3g}, \"\n",
    "      f\"partial R^2={partial_R2_y2:.3f}, std_beta={beta_std_y2:.3f}\")\n",
    "\n",
    "# 同样地做 Y1（-Vc，数值越小=速度越高）\n",
    "y1 = df[\"Y1\"].astype(float)\n",
    "res_y1 = sm.OLS(y1, X).fit(cov_type=\"HC3\")\n",
    "t_D1 = res_y1.tvalues[\"D\"]; pr2_y1 = (t_D1*t_D1)/(t_D1*t_D1 + res_y1.df_resid)\n",
    "Z1 = df[[\"Y1\",\"D\",\"Kpx\",\"Cld\",\"Chx\",\"Lx3\"]].apply(lambda s: (s - s.mean())/s.std(ddof=0))\n",
    "res_y1_std = sm.OLS(Z1[\"Y1\"], sm.add_constant(Z1[[\"D\",\"Kpx\",\"Cld\",\"Chx\",\"Lx3\"]])).fit()\n",
    "print(f\"\\n[Y1=-Vc] coef(D)={res_y1.params['D']:.4g}, t={t_D1:.3f}, p={res_y1.pvalues['D']:.3g}, \"\n",
    "      f\"partial R^2={pr2_y1:.3f}, std_beta={res_y1_std.params['D']:.3f}\")\n",
    "\n",
    "# Y3（平稳性指标）\n",
    "y3 = df[\"Y3\"].astype(float)\n",
    "res_y3 = sm.OLS(y3, X).fit(cov_type=\"HC3\")\n",
    "t_D3 = res_y3.tvalues[\"D\"]; pr2_y3 = (t_D3*t_D3)/(t_D3*t_D3 + res_y3.df_resid)\n",
    "Z3 = df[[\"Y3\",\"D\",\"Kpx\",\"Cld\",\"Chx\",\"Lx3\"]].apply(lambda s: (s - s.mean())/s.std(ddof=0))\n",
    "res_y3_std = sm.OLS(Z3[\"Y3\"], sm.add_constant(Z3[[\"D\",\"Kpx\",\"Cld\",\"Chx\",\"Lx3\"]])).fit()\n",
    "print(f\"\\n[Y3] coef(D)={res_y3.params['D']:.4g}, t={t_D3:.3f}, p={res_y3.pvalues['D']:.3g}, \"\n",
    "      f\"partial R^2={pr2_y3:.3f}, std_beta={res_y3_std.params['D']:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: 偏相关：r(D, Y | Kpx, Cld, Chx, Lx3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过“残差化”做偏相关：先用控制变量回归掉 D 和 Y 的线性影响，再对残差做相关\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "def partial_corr_by_residual(df, ycol):\n",
    "    # 对 y 与 D 分别用 controls 做 OLS，取残差\n",
    "    controls = sm.add_constant(df[[\"Kpx\",\"Cld\",\"Chx\",\"Lx3\"]].astype(float))\n",
    "    ry = sm.OLS(df[ycol].astype(float).values, controls.values).fit().resid\n",
    "    rD = sm.OLS(df[\"D\"].astype(float).values,       controls.values).fit().resid\n",
    "    r, p = pearsonr(rD, ry)\n",
    "    return r, p, len(df) - controls.shape[1] - 1\n",
    "\n",
    "for ycol, yname in [(\"Wear\",\"Y2 磨耗\"), (\"Y1\",\"Y1 = -Vc\"), (\"Y3\",\"Y3 平稳性\")]:\n",
    "    r, p, dof = partial_corr_by_residual(df, ycol)\n",
    "    print(f\"[偏相关] r(D, {yname} | Kpx,Cld,Chx,Lx3) = {r:.3f}, p={p:.3g}, dof={dof}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Λ 型 vs V/一般型 的 Welch t 检验 + 箱线图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "mask_lambda = df[\"D\"] < 0\n",
    "mask_vgen   = ~mask_lambda\n",
    "\n",
    "def group_t(ycol, label):\n",
    "    a = df.loc[mask_lambda, ycol].astype(float)\n",
    "    b = df.loc[mask_vgen,   ycol].astype(float)\n",
    "    t, p = ttest_ind(a, b, equal_var=False)\n",
    "    print(f\"[Welch] {label}: n_Λ={len(a)}, mean_Λ={a.mean():.2f} | n_V={len(b)}, mean_V={b.mean():.2f} | t={t:.2f}, p={p:.3g}\")\n",
    "\n",
    "for col, name in [(\"Wear\",\"Y2 磨耗\"), (\"Y1\",\"Y1=-Vc（数值越小=速度越高）\"), (\"Y3\",\"Y3 平稳性\")]:\n",
    "    group_t(col, name)\n",
    "\n",
    "# 箱线图（对比三目标）\n",
    "plt.figure()\n",
    "plt.boxplot([df.loc[mask_lambda,\"Wear\"], df.loc[mask_vgen,\"Wear\"]], labels=[\"Λ 型(D<0)\",\"V/一般型(D≥0)\"])\n",
    "plt.ylabel(\"磨耗 (Y2)\")\n",
    "plt.title(\"Λ 型 vs V/一般型 | 磨耗分布对比\")\n",
    "plt.grid(True, linewidth=0.3, alpha=0.6)\n",
    "# plt.savefig(\"box_wear_groups.png\", dpi=220, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: RandomForest 回归偏依赖图（1D + 2D）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "\n",
    "X_pd = df[[\"Kpx\", \"D\"]].values\n",
    "y_pd = df[\"Wear\"].values\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=500, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_pd, y_pd)\n",
    "\n",
    "# 1D：Y2 对 D 的偏依赖\n",
    "disp1 = PartialDependenceDisplay.from_estimator(\n",
    "    rf, X_pd, [1],\n",
    "    feature_names=[\"Kpx\",\"D\"],\n",
    "    grid_resolution=40,\n",
    "    percentiles=(0.01, 0.99)\n",
    ")\n",
    "disp1.axes_[0, 0].set_title(\"偏依赖：Y2(磨耗) 对 D\")\n",
    "disp1.figure_.tight_layout()\n",
    "# disp1.figure_.savefig(\"pd_Y2_vs_D.png\", dpi=220, bbox_inches=\"tight\")\n",
    "\n",
    "# 2D PDP：Y2 对 (Kpx, D)\n",
    "disp2 = PartialDependenceDisplay.from_estimator(\n",
    "    rf, X_pd, [(0, 1)],\n",
    "    feature_names=[\"Kpx\", \"D\"],\n",
    "    grid_resolution=32,\n",
    "    percentiles=(0.02, 0.98),\n",
    ")\n",
    "disp2.axes_[0, 0].set_title(\"偏依赖：Y2(磨耗) 对 (Kpx, D)\")\n",
    "disp2.figure_.tight_layout()\n",
    "# disp2.figure_.savefig(\"pd_Y2_vs_Kpx_D.png\", dpi=220, bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: 基于 RF 的等高线图：更直观看“低 Kpx + Λ 型(D<0) 是低磨耗带”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直接用 RF 在网格上预测生成等高线\n",
    "kpx_min, kpx_max = np.quantile(df[\"Kpx\"], [0.01, 0.99])\n",
    "d_min,   d_max   = np.quantile(df[\"D\"],   [0.01, 0.99])\n",
    "\n",
    "gx = np.linspace(kpx_min, kpx_max, 120)\n",
    "gy = np.linspace(d_min,   d_max,   120)\n",
    "GX, GY = np.meshgrid(gx, gy)\n",
    "YY = rf.predict(np.c_[GX.ravel(), GY.ravel()]).reshape(GX.shape)\n",
    "\n",
    "plt.figure()\n",
    "cs = plt.contourf(GX, GY, YY, levels=14)\n",
    "plt.colorbar(cs, label=\"预测磨耗 Y2\")\n",
    "plt.xlabel(\"Kpx\")\n",
    "plt.ylabel(\"D = Lx1 - Lx2（<0 为 Λ 型）\")\n",
    "plt.title(\"随机森林代理下的 Y2 等高线（直观观察低磨耗带）\")\n",
    "plt.grid(True, linewidth=0.3, alpha=0.6)\n",
    "# plt.savefig(\"contour_Y2_Kpx_D.png\", dpi=220, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markdown 占位"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 代码占位"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pypack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
